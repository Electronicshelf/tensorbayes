{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorbayes as tb\n",
    "from tensorbayes.layers import constant, placeholder\n",
    "from tensorbayes.layers import dense, batch_normalization\n",
    "from tensorbayes.layers import sample_gaussian\n",
    "from tensorbayes.utils import show_graph\n",
    "from tensorbayes.utils import progbar\n",
    "from tensorbayes.distributions import normal_log_pdf, bernoulli_log_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# General settings.\n",
    "activate = tf.nn.elu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LadderMerge(zm1, zv1, zm2, zv2, scope):\n",
    "    with tf.name_scope(scope):\n",
    "        with tf.name_scope('variance'):\n",
    "            zp1 = 1.0/zv1\n",
    "            zp2 = 1.0/zv2\n",
    "            zv = 1.0/(zp1 + zp2)\n",
    "        with tf.name_scope('mean'):\n",
    "            zm = (zm1 * zp1 + zm2 * zp2) * zv\n",
    "    return zm, zv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def layer(x, size, scope, bn=True, activation=None):\n",
    "    with tf.variable_scope(scope):\n",
    "        h = dense(x, size, scope='dense')\n",
    "        if bn:\n",
    "            h = batch_normalization(h, phase, scope='bn')\n",
    "        if activation is not None:\n",
    "            h = activation(h)\n",
    "        return h\n",
    "\n",
    "def name(index, suffix):\n",
    "    return 'z{:d}'.format(index) + '_' + suffix\n",
    "    \n",
    "def encode_block(x, h_size, z_size, idx):\n",
    "    with tf.variable_scope(name(idx, 'encode')):\n",
    "        h = layer(x, h_size, 'layer1', activation=activate)\n",
    "        h = layer(h, h_size, 'layer2', activation=activate)\n",
    "    with tf.variable_scope(name(idx, 'encode/likelihood')):\n",
    "        z_m = layer(h, z_size, 'mean')\n",
    "        z_v = layer(h, z_size, 'variance', activation=tf.nn.softplus)\n",
    "    return (z_m, z_v)\n",
    "    \n",
    "def infer_block(likelihood, prior, idx):\n",
    "    with tf.variable_scope(name(idx, 'sample')):\n",
    "        if prior is None:\n",
    "            posterior = likelihood\n",
    "        else:\n",
    "            args = likelihood + prior\n",
    "            posterior = LadderMerge(*args, scope='pwm')\n",
    "        z = sample_gaussian(*posterior, scope='sample')\n",
    "    return z, posterior\n",
    "\n",
    "def decode_block(z_like, z_prior, h_size, x_size, idx):\n",
    "    z, z_post = infer_block(z_like, z_prior, idx)\n",
    "    with tf.variable_scope(name(idx - 1, 'decode')):\n",
    "        h = layer(z, h_size, 'layer1', activation=activate)\n",
    "        h = layer(h, h_size, 'layer2', activation=activate)\n",
    "    with tf.variable_scope(name(idx - 1, 'decode/prior')):\n",
    "        if (idx - 1) == 0:\n",
    "            logits = layer(h, 784, 'logits', bn=False)\n",
    "            return z, z_post, logits\n",
    "        else:\n",
    "            x_m = layer(h, x_size, 'mean')\n",
    "            x_v = layer(h, x_size, 'variance', activation=tf.nn.softplus)\n",
    "            x_prior = (x_m, x_v)\n",
    "            return z, z_post, x_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "phase = placeholder(None, tf.bool, name='phase')\n",
    "x = placeholder((None, 784), name='x')\n",
    "with tf.name_scope('z0'):\n",
    "    z0 = tf.cast(tf.greater(x, tf.random_uniform(tf.shape(x), 0, 1)), tf.float32)\n",
    "\n",
    "# Encode.\n",
    "z1_like = encode_block(z0, 512, 64, idx=1)\n",
    "z2_like = encode_block(z1_like[0], 256, 32, idx=2)\n",
    "z3_like = encode_block(z2_like[0], 128, 16, idx=3)\n",
    "# Decode.\n",
    "z3_prior = (constant(0), constant(1))\n",
    "z3, z3_post, z2_prior = decode_block(z3_like, None, 128, 32, idx=3)\n",
    "z2, z2_post, z1_prior = decode_block(z2_like, z2_prior, 256, 64, idx=2)\n",
    "z1, z1_post, z0_logits = decode_block(z1_like, z1_prior, 512, 784, idx=1)\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    with tf.name_scope('recon'):\n",
    "        recon = -bernoulli_log_pdf(z0, z0_logits)\n",
    "    with tf.name_scope('kl1'):\n",
    "        kl1   = -normal_log_pdf(z1, *z1_prior) + normal_log_pdf(z1, *z1_post)\n",
    "    with tf.name_scope('kl2'):\n",
    "        kl2   = -normal_log_pdf(z2, *z2_prior) + normal_log_pdf(z2, *z2_post)\n",
    "    with tf.name_scope('kl3'):\n",
    "        kl3   = -normal_log_pdf(z3, *z3_prior) + normal_log_pdf(z3, *z3_post)\n",
    "    loss  = recon + kl1 + kl2 + kl3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    show_graph(tf.get_default_graph().as_graph_def())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr = placeholder(None, name='lr')\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(update_ops):\n",
    "    # Ensures that we execute the update_ops before performing the train_step\n",
    "    train_step = tf.train.AdamOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 227.50777, 226.16895]\n",
      "[2, 161.21005, 160.13354]\n"
     ]
    }
   ],
   "source": [
    "history = []\n",
    "iterep = 500\n",
    "for i in range(iterep * 2):\n",
    "    x_train, y_train = mnist.train.next_batch(100)\n",
    "    sess.run(train_step,\n",
    "             feed_dict={'x:0': x_train,\n",
    "                        'phase:0': True,\n",
    "                        'lr:0': 2e-4})\n",
    "    progbar(i, iterep)\n",
    "    if (i + 1) %  iterep == 0:\n",
    "        epoch = (i + 1) // iterep\n",
    "        tr = sess.run(loss, \n",
    "                      feed_dict={'x:0': mnist.train.images,\n",
    "                                 'phase:0': False})\n",
    "        t = sess.run(loss, \n",
    "                     feed_dict={'x:0': mnist.test.images,\n",
    "                                'phase:0': False})\n",
    "        history += [[epoch, tr.mean(), t.mean()]]\n",
    "        print(history[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
